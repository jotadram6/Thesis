Remarks/Corrections/Questions from Sabine: (Following discussion of 21 September)

General form remarks:
1. Check that between paragraphs there is a blank space in the tex file. (Chapter 1 done, Chapter 2 done, Chapter 3 done, Chapter 4 done, Chapter 5 done)
2. Add full stop always at the end of caption (Chapter 1 done, Chapter 2 done, Chapter 3 done, Chapter 4 done, Chapter 5 done)
3. Add reference in figure caption -> Only reference number between brackets without "Taken from" or "From" before the reference (Chapter 1 done, Chapter 2 done, Chapter 3 done, Chapter 4 done, Chapter 5 done)
4. Remove the commas before giving a reference. (Chapter 1 done, Chapter 2 done, Chapter 3 done, Chapter 4 done, Chapter 5 done)
5. Replace "as function of" for "as a function of" -> Sabine asked me to check this with a native English speaker (Chapter 1 done, Chapter 2 done, Chapter 3 done, Chapter 4 done, Chapter 5 done)

############
#Chapter 1:#
############

Equation 1.3: Define lambda(x) (Done) -> More precisely, the covariant potential is not unique and the covariant derivative of a scalar field, $\partial_{\mu}\Lambda(x)$, can always been added

Lines 368-369: Rephrase to clear what are the mentioned probabilities 

Several functions or fields can be related to a given state. These functions, wave functions, can be used as the states to calculate probabilities. -> Several functions or fields can be related to a system. These functions, wave functions, can be used to calculate the probability of a system to be in a given state or the transition probability between states.

Lines 423: Rephrase 

Whatsoever being the theoretical mechanism to give mass to particles one of the most refined theoretical constructs, it leaves some unsolved puzzles in the heart of the SM. -> Whatsoever, even if the mechanism to give mass to particles is one of the most refined theoretical constructs, it leaves some unsolved puzzles in the heart of the SM.

Lines 484: Rephrase "coming from vacuum"

This means, in practical terms, that such field will have a non-zero value in vacuum, leading to a presence of particles coming from the field on vacuum. -> This means, in practical terms, that such field will have a non-zero value in vacuum, i.e. there are particles from the field in vacuum.

Section 1.5: More details on the VLQ theory, specifically compare the model used in later chapters with models with exclusive coupling of T' to third quark generation. Add also results from LEP about existence of a fourth family -> Restriction of only 3 neutrinos

LEP restriction  on number of active neutrinos has been added in the following phrase: A fourth family would introduce a fourth neutrino, this possibility that has been discarded by LEP~\cite{ALEPH:2005ab} if the fourth neutrino couples to the \Z~boson.



Line 681: Rephrase for clarity


############
#Chapter 2:#
############

Line 908-909: Beginning of phrase missing -> Rephrase

where $\sigma_{process}$ is the cross section of the process. -> The constant of proportionality is the cross section of the process, noted as $\sigma_{process}$.

Line 921-922: Rephrase to correct concept of hard interaction

Only in the hard interactions, inelastic scattering, color is exchanged, being the reason to fill up the central rapidity region. -> Only in the hard interactions, inelastic scattering, the central rapidity region is filled up. In proton-proton collisions additionally color is exchanged.

Line 1069: Define/Clarify "both features"

The design of CMS magnet targets both features, it utilizes a large solenoid of 6 m of diameter and 13 m long. -> The design of CMS magnet targets both features, a large solenoid and a strong magnetic field, utilizing a solenoid of 6 m of diameter and 13 m long.

Line 1104: Correct "pt" notation (Done). And clear up the concept of leptons and photon isolation.



Line 1126: Explain what is a "Dee" (CMS jargon)

Each endcap is divided in two equal semicircles, called 'Dee's.

Page 56: Usage of HT and MHT without definition.

Changed phrase to be more explicit: Therefore, it relies on very fast reconstruction of objects coming from this subsystems: muons, electrons, photons, jets, total energy and total hadronic energy (with their corresponding total missing energy and hadronic missing energy). The total energy is calculated as the sum of all the objects in the event, while for the hadronic energy only calojets are considered in the sum.

Line 1309: Move to vertex reconstruction section (Done)

Line 1405-1406: Rephrase

The formerly described jet algorithms are both collinear and infrared safe, well reconstructing jets to solely initial partons. -> The jet algorithms described in previous sections are collinear and infrared safe. 

Line 1416: Replace "expected area" by "\piR^2" (Done)

Figure 2.27: Define "HF" in the caption. -> Text added to the caption: In the legend, HF stands for the Hadron Forward Calorimeter.

############
#Chapter 3:#
############

Line 1500: Add full effective branching ratio of T' in the full hadronic channel

Using these three branching ratios an expected number of events of \Tp~into 5 quarks (or jets) of around 700 events is obtained. -> Using these three branching ratios, the $Br(T'\to 3b, 2j)=37$\%. Thus the expected number of events of \Tp~into 5 quarks (or jets) is of around 700 events.

Section 3.1: Add generators references (Done)

Line 1527: Explain what is "integration troubles"

the mass of the di--lepton pair was required to satisfy $M_{ll}>50$~\GeVcc~in order to avoid integration troubles. -> the mass of the di--lepton pair was required to satisfy $M_{ll}>50$~\GeVcc~in order to avoid integration troubles (when the di--lepton invariant mass approaches zero the cross-section diverges).

Line 1533: Explain the choice of parameters -> Include reference where the benchmark point was studied

These parameters correspond to a benchmark point similar to the one defined in~\cite{Cacciapaglia:2011fx}, it was set to obtain a VLQ mixed with light and heavy SM quark generations and a \Tp~mass close to 700~\GeVcc.

Figure 3.2: Small axis labels (resize or bold to ameliorate reading). Say a word in caption about QCD that is not very visible. -> Bold added to labels. Phrase added to caption: QCD background is on top of the stack of backgrounds.

Chapter 3: Add reference of pheno paper at the beginning. (Done)

Line added: A majority of the results exposed in this chapter are part of the reference~\cite{Beauceron:2014ila}.

Section 3.3: Explain procedure for the determination of the cut values.

The different criteria have been chosen in order to increase the discrimination of signal from background. The objective of the study is not to obtain the best possible discrimination but moreover to illustrate a possible selection to extract the signal and to give a qualitative understanding of signal characteristics.

Line 1609: Change "\Delta R_{jj}" for "\Delta R_{bb}"

Changed

Line 1627: Change "central" for "close in \phi"

Changed

Line 1670-1673: Rephrase/Explain

These fluctuations due to the poor statistics can change the final estimate of the number of background events entering the peak of the signal, and the error is partially accounted for in the statistical error. -> These fluctuations due to the poor statistics can change the final estimate of the number of background events entering the peak of the signal.

Line 1684: (Not mandatory) Add efficiencies of cuts with wider T' width

Chapter 3: Add paragraph at the end about the importance of studying model where the T' is mixed to the three generations.

It is important to stress that the present study, as the CMS analysis that will be presented afterward, rely in a VLQ model that has been poorly explored in experiments. This model allows the VLQ to be mixed to the three generations of SM quarks, enhancing the production cross section in proton-proton collisions. The most common VLQ models assume that the top-partner mixes preferentially to third SM-quark generation. The model used in this work represents then a generalization with respect to the most widely used models in the literature.

Line 1696: Missing verb

In chapter~\ref{chap:search}, a data analysis using data collected by CMS experiment during run 1. -> In chapter~\ref{chap:search}, a data analysis using data collected by CMS experiment during run 1 is presented.

############
#Chapter 4:#
############

Line 1747: Specify what is "this" in the phrase context -> Remove line or rephrase

Phrase removed.

Line 1768: Transition between both paragraphs is missing

Small paragraph added: The knowledge of the proton content allows to compute the cross section of processes proton-proton collisions. This cross section depends of the momentum carried by each parton inside the parton, and are modulated by the probability of the interaction between different quarks during the collision.

Figure 4.4: Explain color code of the figure.

Description added to the caption of the figure: The biggest green ellipses, preceded by three green arrows, represent the initial protons. The small green circles inside them represent the partons inside the protons. The big red circle, with small red circles inside, represent the hard interaction from partons (in blue lines). The hard interaction produces three particles, red full small circles, that decay afterward. The red lines represent the decay products from the particles produced in the hard interaction, and the additional particles produced from showering. Final hadrons are drawn in the most exterior part of the graph. These final hadrons are represented by the small full green circles.

Chapter 4: 
	Add, if possible, the gain on cpu time with madspin for ttbar production



	Explain better how Qcut and QXcut are done before generation. And clarify how the first is at pythia level and the second at madgraph.

Two phrases added: 
$Q^{X}_{cut}$ will be used to refer to it. This cut is applied at generator level, what means that MadGraph will only deliver events where every pair of partons satisfy this requirement.

$Q_{cut}$ is also a generator cut at Pythia level. Pythia will give then only events where every pair of hadrons pass this criterion.

	Explain better/Add details about merging procedure and DJR study. (DJR is really a variable?)

Rephrased and added additional clarifications.

Line 1993-1996: Replace "minimal kt" for "minimal kt distance"

Replaced.

Figure 4.15, 4.16: Increase size -> Done

############
#Chapter 5:#
############

Line 2117: Define what is "pt hat" (CMS jargon)

Added explanation: (for initial partons \pt~ranges)

Line 2141: Add one or two lines to describe more PAT

Tow lines added: PAT simplifies access to reconstructed objects and tools developed for analyses. It constitutes a common work-ground where analysts can find a simplified access to event content and to the full set of CMS tools. 

Line 2171: Explain why trigger is an or between pt>32, pt>36, pt>40 ...

Line added: To obtain a fully unprescaled trigger selection, on top of the loosest trigger requirement that is prescaled, tighter unprescaled trigger requirements were added.

Figure 5.1: Definition of number of interactions for data and add a reference

Line added: For data, the true number of interactions represents the expected number of interactions per crossing for a given lumi section from the average bunch instantaneous luminosity with respect to the total inelastic cross section.

Line 2201: Recall that backgrounds are estimated from data.

Line added: The MC samples are used in this analysis only for illustration purposes, as final background estimation has been derived directly from data.

Line 2205: Precise and rephrase to say that the two sets of QCD samples are weighted to half of the luminosity instead of saying mean values

The QCD \HT~binned and \pt~hat samples were normalized to their mean value with respect to the luminosity observed in the data. -> The QCD \HT~binned and \pt~hat samples were normalized to half the luminosity observed in the data.

Figure 5.5: Why high eta disagreement? Perhaps add pt vs eta plots for each jet.

These differences are due to the trigger simulation that does not correspond exactly to the behavior of trigger on data. I propose to add the following text: Additionally, in the $\eta$ distributions of jets a disagreement between data and MC is visible for \etag{3}. This disagreement is caused by the simulation of the trigger on MC, that do not correspond exactly with the behavior of real trigger in data. This mismatch of the trigger in MC is a motivations to estimate backgrounds from data instead of using MC.

Figure 5.6: (Not mandatory) Add HT data/MC comparison with only HT binned samples

Table 5.4: Missing sqrt for "S/(S+B)" -> It is really "S/sqrt(S+B)"

Corrected

Equation 5.5: Specify that the efficiencies where calculated from the whole samples and not event per event

Phrase added: The b-tagging efficiencies are not calculated in an event per event basis but from the whole MC sample being considered. 

Line 2294: Specify conditions of the study from where the values are coming.

Phrase added: The Higgs boson width and mass were extracted from an analysis looking for the associated production of a \Z~and Higgs boson, with the \Z~decaying into leptons and the Higgs boson in \bbbar. The top quark and \W~boson width and mass were taken from an analysis looking for \ttbar~resonances with one top quark decaying in the leptonic channel and the second top quark going into the hadronic channel.

Line 2352: Specify that the cut values were taken from a scan optimization -> Add, after all cuts, optimization range, step...



Figures for variables of chapter 5 selection: (Not mandatory) Add vertical lines to show the cut value.

I'll prefer to leave the plots in their current state. However I'll add the lines for the presentation of the defense.

Figure 5.19: Bin 9?

Bin 9 missing, now added to the plot.

Page 140: (Not mandatory) Add T' mass for all signal mass points after full selection



For Chapter 5: (not mandatory, but to ease reading) Redo paging to close up tables and figure to the text where they are cited.




Line 2491: Specify that number of events are unweighted wrt lumi.

Finally, for completeness, tables~\ref{tab:cutflowQCD},~\ref{tab:cutflowTop} and~\ref{tab:cutflowDibosonSignal} show the number of unweighted events for all the MC samples used in the analysis at each step of the selection. -> Finally, for completeness, tables~\ref{tab:cutflowQCD},~\ref{tab:cutflowTop} and~\ref{tab:cutflowDibosonSignal} show the number of unweighted events, with respect to lumi, for all the MC samples used in the analysis at each step of the selection.

Page 144: Define M(5j)

Despite of these difficulties, a method to derive from the data the shape of backgrounds contribution to $M(5j)$ after full selection and one additional method to estimate its normalization have been derived. -> Despite of these difficulties, a method to derive from the data the shape of backgrounds contribution to $M(5j)$, the invariant mass of the 5-jets chosen to reconstruct the \Tp, after full selection and one additional method to estimate its normalization have been derived.

Title of section 5.4.1: Change to "Method for background shape estimation"

Changed

Line 2511-2518: Rephrase or remove mention of chi2 cut.

The second most stringent cut is the $\chi^{2}$ selection criterion, it selects 8\% of multijet events and 32\% of \ttbar~events that passed the b-tagged jets multiplicity selection. This is why the number of b-tagged jets was taken as variable suited to define the control sample. -> Reason why the number of b-tagged jets was taken as variable suited to define the control sample.

Line 2535: Define "both"

Phrase changed: both samples -> signal and control samples 

Figure 5.29: Be more explicit about errors for samples with zero entries.

Added to caption: To correctly estimate the associated errors, for each MC sample an error of 1.8 events (times the corresponding weight) should be added to each bin with zero entries.

Figure 5.38: Change color of control sample or increase size of figure because the control sample is hard to see.

I changed the color for a darker gray and increased the size of the plots.

Systematics:
	Why the error of the c-jets is taken as the double of b-jets?

The b-tagging working group in CMS has not put in place an accurate method to measure the charm mistag rate. I propose to add the following information: The b-tagging working group has put in place an accurate method to measure the b-jet tag rate. However, a method to measure the c-jet mistag rate has not been developed. As the c-jet b-tagging efficiency is quite high (~20\%) for the medium working point using the CSV algorithm, the b-tagging working group has recommended to use the same scale factors for b and c-jets, but doubling the uncertainty for c-jets to account the lack of a proper method to determine them.

	Try to explain better that when the statistical error is bigger than the systematic, the statistical error is taken as the value for the systematic uncertainty

In the same table are shown the statistical uncertainties of signal yields in percentage. In the calculation of systematics for signal a conservative approach will be followed. If a source of systematic uncertainty is found to be smaller than the statistical uncertainties of the yield, the latter will be taken as the value of the systematic uncertainty.

	(Not mandatory) Add statistic errors to figure 5.41 (and other similar figures)

Done

	Line 2701-2719: Simplify vocabulary and explanation of PDF systematics

Replace:
Another source of uncertainties for MC signal samples is related to the PDF and $\alpha_{S}$ used in the simulation. MC signal samples were produced with the PDF set CTEQ6.6 with the best fit values among PDF members. The possible variations from all 44 members of CTEQ6.6 to obtain an overall systematic effect on signal yields have been considered. In addition two additional PDF sets have been considered: MSTW2008 and NNPDF2.0. For MSTW2008 40 eigenvectors and for NNPDF2.0 50 replicas were added in quadrature. For the $\alpha_{s}$, 1-$\sigma$ variations were considered around the central value for each PDF set: $\alpha_{s}(M_{Z})=0.118$ for CTEQ6.6, $\alpha_{s}(M_{Z})=0.12018$ for MSTW2008 and $\alpha_{s}(M_{Z})=0.119$ for NNPDF2.0. To calculate the observable with the varied parameters of the PDF a reweighting method was used. A weight was calculated for each member/eigenvector/replica $j$, in equation~\ref{eq:pdfweights} where $x_{1,2}$ is the fraction of the momentum carried by the two initial partons entering the hard interaction, $f_{1,2}$ is their corresponding pdg code, and $Q$ is the scale. The weights were used to calculate the yields and then the systematics for the cases of CTEQ6.6 and MSTW2008 were given by equation~\ref{eq:quadsum} while for NNPDF2.0 were given by equation~\ref{eq:quadsumNNPDF}. In these equations $\mathcal{O}^{j}$ is the observable evaluated for the eigenvector $j$, being $j=0$ for the nominal value, and $C=1.64485$ for CTEQ6.6 to correctly obtain just 1-$\sigma$ variation, and $C=1$ for MSTW2008.

for:
Another source of uncertainties for MC signal samples is related to the PDF and $\alpha_{S}$ used in the simulation. MC signal samples were produced with the PDF set CTEQ6.6 with the best fit values among PDF members. The possible variations from all 44 members of CTEQ6.6 to obtain an overall systematic effect on signal yields have been considered. In addition two additional PDF sets have been considered: MSTW2008 and NNPDF2.0. For MSTW2008 40 members and for NNPDF2.0 50 members were added in quadrature. For the $\alpha_{s}$, 1-$\sigma$ variations were considered around the central value for each PDF set: $\alpha_{s}(M_{Z})=0.118$ for CTEQ6.6, $\alpha_{s}(M_{Z})=0.12018$ for MSTW2008 and $\alpha_{s}(M_{Z})=0.119$ for NNPDF2.0. 

In principle, to calculate the systematic variations when changing the PDF set used in the MC simulation, it should be required to regenerate the MC simulation with each PDF member. Such a procedure is inefficient and requires a high availability of computing resources and time. Therefore, to calculate the observable with the varied members of the PDF a reweighting method was used. A weight was calculated for each member $j$, in equation~\ref{eq:pdfweights} where $x_{1,2}$ is the fraction of the momentum carried by the two initial partons entering the hard interaction, $f_{1,2}$ is their corresponding pdg code, and $Q$ is the scale. The weights were used to calculate the yields and then the systematics for the cases of CTEQ6.6 and MSTW2008 were given by equation~\ref{eq:quadsum} while for NNPDF2.0 were given by equation~\ref{eq:quadsumNNPDF}. In these equations $\mathcal{O}^{j}$ is the observable evaluated for the member $j$, being $j=0$ for the nominal value, and $C=1.64485$ for CTEQ6.6 to correctly obtain 1-$\sigma$ variation, and $C=1$ for MSTW2008.

	Line 2723: Change 4% for 3%

Changed

	Line 2730: Justification of 5% variation of inelastic cross section variation for PU systematics calculation

Using different measurements of the total inelastic cross section, as in~\cite{Chatrchyan:2013gfi, CMS:2012sua, Antchev:2011vs}, the best fit value of the inelastic cross section for 2012 is 69.4 mb, with an approximate error of 3\%. Combining this error with the uncertainty on the luminosity (2.6\%), the total uncertainty on the estimated number of interactions is 3.9\%. However, as some details in the MC simulations used for the cross section measurement are difficult to interpret, a conservative error of 5\% was taken.

	Line 2749-2756: Add reference to figure from where fig 5.44 is coming

Phrase added to caption: This figure corresponds to the projection on the y-axis of the ratio between signal and control samples shown in top right plot of figure~\ref{fig:StageWPData}.

	Line 2766-2770: Reverse order of the two phrases.

Also, it was shown in the last section that the highest signal contamination expected is of 7\% for 750~\GeVcc~and 800~\GeVcc mass points. Summing in quadrature the different sources of systematic uncertainties for the background from the estimation methods, the total uncertainty on background is 39\%. -> Summing in quadrature the different sources of systematic uncertainties for the background from the estimation methods, the total uncertainty on background is 39\%. Also, it was shown in the last section that the highest signal contamination expected is of 7\% for 750~\GeVcc~and 800~\GeVcc mass points.

Line 2864: Explicit that is to all 3 generation mixings.

Done -> In particular, the model used for the generation of the signal MC samples have been constructed with a \Tp~that mixes with all generations of SM quarks.

Fig 5.50: CMS figure is small -> Re-size (Done)

Question for the defense: How to decrease the uncertainties of the background estimation methods?
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Grouped by categroies:

%%%%%%%%%%%%%%%%%
Corrections:%%%%%
%%%%%%%%%%%%%%%%%

1. Check that between paragraphs there is a blank space in the tex file.
2. Add full stop always at the end of caption
3. Add reference in figure caption -> Only reference number between brackets without "Taken from" or "From" before the reference.
4. Remove the commas before giving a reference.
5. Replace "as function of" for "as a function of" -> Sabine asked me to check this with a native English speaker 

Equation 1.3: Define lambda(x)

Line 921-922: Rephrase to correct concept of hard interaction

Line 1104: Correct "pt" notation. And clear up the concept of leptons and photon isolation.

Line 1993-1996: Replace "minimal kt" for "minimal kt distance"

Figure 4.15, 4.16: Increase size

Table 5.4: Missing sqrt for "S/(S+B)" -> It is really "S/sqrt(S+B)"

Title of section 5.4.1: Change to "Method for background shape estimation"

Systematics:
        (Not mandatory) Add statistic errors to figure 5.41 (and other similar figures)
        Line 2723: Change 4% for 3%
        Line 2749-2756: Add reference to figure from where fig 5.44 is coming
        Line 2766-2770: Reverse order of the two phrases.


%%%%%%%%%%%%%%%%
Rephrasings:%%%%
%%%%%%%%%%%%%%%%

Lines 368-369: Rephrase to clear what are the mentioned probabilities

Lines 423: Rephrase "coming from vacuum"

Section 1.5: More details on the VLQ theory, specifically compare the model used in later chapters with models with exclusive coupling of T' to third quark generation. Add also results from LEP about existence of a fourth family -> Restriction of only 3 neutrinos

Line 681: Rephrase for clarity

Line 908-909: Beginning of phrase missing -> Rephrase

Line 1069: Define/Clarify "both features"

Line 1126: Explain what is a "Dee" (CMS jargon)

Page 56: Usage of HT and MHT without definition.

Line 1309: Moe to vertex reconstruction section

Line 1405-1406: Rephrase

Line 1416: Replace "expected area" by "\piR^2"

Figure 2.27: Define "HF" in the caption.

Line 1500: Add full effective branching ratio of T' in the full hadronic channel

Section 3.1: Add generators references

Line 1527: Explain what is "integration troubles"

Line 1533: Explain the choice of parameters -> Include reference where the benchmark point was studied

Figure 3.2: Small axis labels (resize or bold to ameliorate reading). Say a word in caption about QCD that is not very visible.

Chapter 3: Add reference of pheno paper at the beginning.

Line 1609: Change "\Delta R_{jj}" for "\Delta R_{bb}"

Line 1627: Change "central" for "close in \phi"

Line 1670-1673: Rephrase/Explain

Chapter 3: Add paragraph at the end about the importance of studying model where the T' is mixed to the three generations.

Line 1696: Missing verb

Line 1747: Specify what is "this" in the phrase context -> Remove line or rephrase

Line 1768: Transition between both paragraphs is missing

Figure 4.4: Explain color code of the figure.

Chapter 4: 
        Explain better how Qcut and QXcut are done before generation. And clarify how the first is at pythia level and the second at madgraph.
        Explain better/Add details about merging procedure and DJR study. (DJR is really a variable?)

Line 2117: Define what is "pt hat" (CMS jargon)

Line 2141: Add one or two lines to describe more PAT

Line 2201: Recall that backgrounds are estimated from data.

Line 2205: Precise and rephrase to day that the two sets of QCD samples are weighted to half of the luminosity instead of saying mean values

Equation 5.5: Specify that the efficiencies where calculated from the whole samples and not event per event

Line 2294: Specify conditions of the study from where the values are coming.

Line 2352: Specify that the cut values were taken from an scan optimization -> Add, after all cuts, optimization range, step...

For Chapter 5: (not mandatory, but to ease reading) Redo paging to close up tables and figure to the text where they are cited.

Line 2491: Specify that number of events are unweighted wrt lumi.

Page 144: Define M(5j)

Line 2511-2518: Rephrase or remove mention of chi2 cut.

Line 2535: Define "both"

Figure 5.29: Be more explicit about errors for samples with zero entries.

Figure 5.38: Change color of control sample or increase size of figure because the control sample is hard to see.

Systematics:
        Try to explain better that when the statistical error is bigger than the systematic, the statistical error is taken as the value for the systematic uncertainty
        Line 2701-2719: Simplify vocabulary and explanation of PDF systematics

Line 2864: Explicit that is to all 3 generation mixings.

Fig 5.50: CMS figure is small -> Re-size


%%%%%%%%%%%%%%%
Questions:%%%%%
%%%%%%%%%%%%%%%

Section 3.3: Explain procedure for the determination of the cut values. -> Lines added:

I propose to add the following information: The different criteria have been chosen in order to increase the discrimination of signal from background. The objective of the study was not to obtain the best possible discrimination but moreover to illustrate a possible selection to extract the signal and to give a qualitative understanding of signal characteristics.

Line 1684: (Not mandatory) Add efficiencies of cuts with wider T' width

I'm currently retrieving this information.

Chapter 4: 
        Add, if possible, the gain on cpu time with madspin for ttbar production

I have already retrieved the time taken to generate 100 events with MadSpin. I'm recalculating the time needed to generate the same amount of events with MadGraph without MadSpin.

Line 2171: Explain why trigger is an or between pt>32, pt>36, pt>40 ...

The lowest trigger requirement is prescaled, then I propose to add the following phrase: To obtain a fully unprescaled trigger selection, on top of the loosest trigger requirement that is prescaled, tighter trigger requirements were added.

Figure 5.1: Definition of number of interactions for data and add a reference

I propose to add the following phrase: For data, the true number of interactions represents the expected number of interactions per crossing for a given lumi section from the average bunch instantaneous luminosity with respect to the total inelastic cross section.

Figure 5.5: Why high eta disagreement? Perhaps add pt vs eta plots for each jet.

These differences are due to the trigger simulation that does not correspond exactly to the behavior of trigger on data.

Figure 5.6: (Not mandatory) Add HT data/MC comparison with only HT binned samples

I'm currently working on the preparation of this plot. I'll send it to you during the week.

Figures for variables of chapter 5 selection: (Not mandatory) Add vertical lines to show the cut value.

I'll prefer to leave the plots in their current state. However I'll add the lines for the presentation of the defense.

Figure 5.19: Bin 9?

Bin 9 was missing, now I added it to the plot.

Page 140: (Not mandatory) Add T' mass for all signal mass points after full selection

I did not add the plots after full selection because I have already shown the plots right after reconstruction of the T' (figure 5.14) and a table with the results from a gaussian fit of each mass point after full selection (table 5.6). I think, with this in mind, that introducing the same plots after full selection could be doubling the information. However, I can send you the plots privately.

Systematics:
        Why the error of the c-jets is taken as the double of b-jets?

The b-tagging working group in CMS has not put in place an accurate method to measure the charm mistag rate. I propose to add the following information: The b-tagging working group has put in place an accurate method to measure the b-jet tag rate. However, a method to measure the c-jet mistag rate has not been developed. As the c-jet b-tagging efficiency is quite high (~20\%) for the medium working point using the CSV algorithm, the b-tagging working group has recommended to use the same scale factors for b and c-jets, but doubling the uncertainty for c-jets to account the lack of a proper method to determine them.

        Line 2730: Justification of 5% variation of inelastic cross section variation for PU systematics calculation

Using different measurements of the total inelastic cross section, as in~\cite{Chatrchyan:2013gfi, CMS:2012sua, Antchev:2011vs}, the best fit value of the inelastic cross section for 2012 is 69.4 mb, with an approximate error of 3\%. Combining this error with the uncertainty on the luminosity (2.6\%), the total uncertainty on the estimated number of interactions is 3.9\%. However, as some details in the MC simulations used for the cross section measurement are difficult to interpret, a conservative error of 5\% was taken.
